# app.py

import streamlit as st
import pandas as pd
import re
import io
from typing import Optional
from sqlalchemy import text

# LangChain + Gemini
from langchain_openai import ChatOpenAI
from langchain_community.utilities import SQLDatabase
from langchain.agents import create_sql_agent
from langchain.agents.agent_toolkits import SQLDatabaseToolkit
from langchain.chains import create_sql_query_chain

#from langchain_google_genai import ChatGoogleGenerativeAI
#from langchain_community.utilities import SQLDatabase
#from langchain.agents import create_sql_agent
#from langchain.agents.agent_toolkits import SQLDatabaseToolkit
#from langchain.chains import create_sql_query_chain

# MicrÃ³fono en vivo (frontend) + fallback SR
from streamlit_mic_recorder import speech_to_text, mic_recorder
import speech_recognition as sr

# Agente de Correo
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.application import MIMEApplication
import json

# ============================================
# 0) ConfiguraciÃ³n de la PÃ¡gina y TÃ­tulo
# ============================================
st.set_page_config(page_title="IANA para Automundial", page_icon="logo_automundial.png", layout="wide")

col1, col2 = st.columns([1, 4])
with col1:
    st.image("logo_automundial.png", width=120)
with col2:
    st.title("IANA: Tu Asistente IA para AnÃ¡lisis de Datos")
    st.markdown("Soy la red de agentes IA de **Automundial**. Hazme una pregunta sobre los datos de tu negocio.")

# ============================================
# 1) ConexiÃ³n a la Base de Datos y LLMs
# ============================================

@st.cache_resource
def get_database_connection():
    with st.spinner("ğŸ›°ï¸ Conectando a la base de datos de automundial..."):
        try:
            creds = st.secrets["db_credentials"]
            uri = f"mysql+pymysql://{creds['user']}:{creds['password']}@{creds['host']}/{creds['database']}"
            engine_args = {"pool_recycle": 3600, "pool_pre_ping": True}
            db = SQLDatabase.from_uri(uri, include_tables=["automundial"], engine_args=engine_args)
            st.success("âœ… ConexiÃ³n a la base de datos establecida.")
            return db
        except Exception as e:
            st.error(f"Error al conectar a la base de datos: {e}")
            return None

@st.cache_resource
def get_llms():
    with st.spinner("ğŸ¤ Inicializando la red de agentes IANA..."):
        try:
            api_key = st.secrets["openai_api_key"]
            model_name = "gpt-4o"
            llm_sql = ChatOpenAI(model=model_name, temperature=0.1, openai_api_key=api_key)
            llm_analista = ChatOpenAI(model=model_name, temperature=0.1, openai_api_key=api_key)
            llm_orq = ChatOpenAI(model=model_name, temperature=0.0, openai_api_key=api_key)
            llm_validador = ChatOpenAI(model=model_name, temperature=0.0, openai_api_key=api_key)

            #api_key = st.secrets["google_api_key"]
            #common_config = dict(temperature=0.1, google_api_key=api_key)
            #llm_sql = ChatGoogleGenerativeAI(model="gemini-1.5-pro", **common_config)
            #llm_analista = ChatGoogleGenerativeAI(model="gemini-1.5-pro", **common_config)
            #llm_orq = ChatGoogleGenerativeAI(model="gemini-1.5-pro", temperature=0.0, google_api_key=api_key)
            #llm_validador = ChatGoogleGenerativeAI(model="gemini-1.5-pro", temperature=0.0, google_api_key=api_key)
            
            st.success("âœ… Agentes de IANA listos.")
            return llm_sql, llm_analista, llm_orq, llm_validador
        except Exception as e:
            st.error(f"Error al inicializar los LLMs. Revisa tu API key. Detalle: {e}")
            return None, None, None, None

db = get_database_connection()
llm_sql, llm_analista, llm_orq, llm_validador = get_llms()

@st.cache_resource
def get_sql_agent(_llm, _db):
    if not _llm or not _db: return None
    with st.spinner("ğŸ› ï¸ Configurando agente SQL de IANA..."):
        toolkit = SQLDatabaseToolkit(db=_db, llm=_llm)
        agent = create_sql_agent(llm=_llm, toolkit=toolkit, verbose=False, top_k=1000)
        st.success("âœ… Agente SQL configurado.")
        return agent

agente_sql = get_sql_agent(llm_sql, db)

# ============================================
# 1.b) Reconocedor de Voz (fallback local)
# ============================================

@st.cache_resource
def get_recognizer():
    r = sr.Recognizer()
    r.energy_threshold = 300
    r.dynamic_energy_threshold = True
    return r

def transcribir_audio_bytes(data_bytes: bytes, language: str) -> Optional[str]:
    try:
        r = get_recognizer()
        with sr.AudioFile(io.BytesIO(data_bytes)) as source:
            audio = r.record(source)
        texto = r.recognize_google(audio, language=language)
        return texto.strip() if texto else None
    except Exception:
        return None

# ============================================
# 2) Agente de Correo (LÃ³gica Mejorada)
# ============================================

def extraer_detalles_correo(pregunta_usuario: str) -> dict:
    st.info("ğŸ§  El agente de correo estÃ¡ interpretando tu solicitud...")
    
    # Cargar la "agenda de contactos" desde los secretos
    contactos = dict(st.secrets.get("named_recipients", {}))
    default_recipient_name = st.secrets.get("email_credentials", {}).get("default_recipient", "")
    
    prompt = f"""
    Tu tarea es analizar la pregunta de un usuario y extraer los detalles para enviar un correo. Tu output DEBE SER un JSON vÃ¡lido.

    Agenda de Contactos Disponibles: {', '.join(contactos.keys())}

    Pregunta del usuario: "{pregunta_usuario}"

    Instrucciones para extraer:
    1.  `recipient_name`: Busca un nombre de la "Agenda de Contactos" en la pregunta. Si encuentras un nombre (ej: "Oscar"), pon ese nombre aquÃ­. Si encuentras una direcciÃ³n de correo explÃ­cita (ej: "test@test.com"), pon la direcciÃ³n completa aquÃ­. Si no encuentras ni nombre ni correo, usa "default".
    2.  `subject`: Crea un asunto corto y descriptivo basado en la pregunta.
    3.  `body`: Crea un cuerpo de texto breve y profesional para el correo.

    Ejemplo:
    Pregunta: "envÃ­a el reporte a Oscar por favor"
    JSON Output:
    {{
        "recipient_name": "Oscar",
        "subject": "Reporte de Datos Solicitado",
        "body": "Hola, como solicitaste, aquÃ­ tienes el reporte con los datos."
    }}
    
    JSON Output para la pregunta actual:
    """
    
    try:
        response = llm_analista.invoke(prompt).content
        json_response = response.strip().replace("```json", "").replace("```", "").strip()
        details = json.loads(json_response)
        
        recipient_identifier = details.get("recipient_name", "default")
        
        # Resolver el identificador a un correo real
        if "@" in recipient_identifier:
            final_recipient = recipient_identifier  # Ya es un correo
        elif recipient_identifier in contactos:
            final_recipient = contactos[recipient_identifier] # Buscar en la agenda
        else:
            final_recipient = default_recipient_name # Usar el por defecto

        return {
            "recipient": final_recipient,
            "subject": details.get("subject", "Reporte de Datos - IANA"),
            "body": details.get("body", "Adjunto encontrarÃ¡s los datos solicitados.")
        }
    except Exception as e:
        st.warning(f"No pude interpretar los detalles del correo (error: {e}), usarÃ© los valores por defecto.")
        return {
            "recipient": default_recipient_name,
            "subject": "Reporte de Datos - IANA",
            "body": "Adjunto encontrarÃ¡s los datos solicitados."
        }


def enviar_correo_agente(recipient: str, subject: str, body: str, df: Optional[pd.DataFrame] = None):
    with st.spinner(f"ğŸ“§ Enviando correo a {recipient}..."):
        try:
            creds = st.secrets["email_credentials"]
            sender_email = creds["sender_email"]
            sender_password = creds["sender_password"]
            
            msg = MIMEMultipart()
            msg['From'] = sender_email
            msg['To'] = recipient
            msg['Subject'] = subject
            msg.attach(MIMEText(body, 'plain'))
            
            if df is not None and not df.empty:
                csv_buffer = io.StringIO()
                df.to_csv(csv_buffer, index=False)
                attachment = MIMEApplication(csv_buffer.getvalue(), _subtype='csv')
                attachment.add_header('Content-Disposition', 'attachment', filename="datos_iana.csv")
                msg.attach(attachment)
            
            with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:
                server.login(sender_email, sender_password)
                server.send_message(msg)
            
            st.success(f"âœ… Correo enviado exitosamente a {recipient}!")
            return {"texto": f"Â¡Listo! El correo fue enviado a {recipient}."}
            
        except Exception as e:
            st.error(f"âŒ No se pudo enviar el correo. Error: {e}")
            return {"tipo": "error", "texto": f"Lo siento, no pude enviar el correo. Detalle del error: {e}"}

# ============================================
# 3) Funciones Auxiliares y Agentes (SIN CAMBIOS)
# ============================================
# (Todas las funciones desde _coerce_numeric_series hasta responder_conversacion se mantienen igual)
def _coerce_numeric_series(s: pd.Series) -> pd.Series:
    s2 = s.astype(str).str.replace(r'[\u00A0\s]', '', regex=True).str.replace(',', '', regex=False).str.replace('$', '', regex=False).str.replace('%', '', regex=False)
    try: return pd.to_numeric(s2)
    except Exception: return s
def get_history_text(chat_history: list, n_turns=3) -> str:
    if not chat_history or len(chat_history) <= 1: return ""
    history_text = []
    relevant_history = chat_history[-(n_turns * 2 + 1) : -1]
    for msg in relevant_history:
        content = msg.get("content", {}); text_content = ""
        if isinstance(content, dict): text_content = content.get("texto", "")
        elif isinstance(content, str): text_content = content
        if text_content:
            role = "Usuario" if msg["role"] == "user" else "IANA"
            history_text.append(f"{role}: {text_content}")
    if not history_text: return ""
    return "\n--- Contexto de ConversaciÃ³n Anterior ---\n" + "\n".join(history_text) + "\n--- Fin del Contexto ---\n"
def markdown_table_to_df(texto: str) -> pd.DataFrame:
    lineas = [l.rstrip() for l in texto.splitlines() if l.strip().startswith('|')]
    if not lineas: return pd.DataFrame()
    lineas = [l for l in lineas if not re.match(r'^\|\s*-{2,}', l)]
    filas = [[c.strip() for c in l.strip('|').split('|')] for l in lineas]
    if len(filas) < 2: return pd.DataFrame()
    header, data = filas[0], filas[1:]
    max_cols = len(header); data = [r + ['']*(max_cols - len(r)) if len(r) < max_cols else r[:max_cols] for r in data]
    df = pd.DataFrame(data, columns=header)
    for c in df.columns: df[c] = _coerce_numeric_series(df[c])
    return df
def _df_preview(df: pd.DataFrame, n: int = 5) -> str:
    if df is None or df.empty: return ""
    try: return df.head(n).to_markdown(index=False)
    except Exception: return df.head(n).to_string(index=False)
def interpretar_resultado_sql(res: dict) -> dict:
    df = res.get("df")
    if df is not None and not df.empty and res.get("texto") is None:
        if df.shape == (1, 1):
            valor = df.iloc[0, 0]; nombre_columna = df.columns[0]
            res["texto"] = f"La respuesta para '{nombre_columna}' es: **{valor}**"
            st.info("ğŸ’¡ Resultado numÃ©rico interpretado para una respuesta directa.")
    return res
def _asegurar_select_only(sql: str) -> str:
    sql_clean = sql.strip().rstrip(';')
    if not re.match(r'(?is)^\s*select\b', sql_clean): raise ValueError("Solo se permite ejecutar consultas SELECT.")
    sql_clean = re.sub(r'(?is)\blimit\s+\d+\s*$', '', sql_clean).strip()
    return sql_clean

def ejecutar_sql_real(pregunta_usuario: str, hist_text: str):
    st.info("ğŸ¤– El agente de datos estÃ¡ traduciendo tu pregunta a SQL...")
    
    prompt_con_instrucciones = f"""
    Tu tarea es generar una consulta SQL limpia (SOLO SELECT) sobre la tabla `automundial` para responder la pregunta del usuario.

    ---
    <<< NUEVA REGLA: PARA VALORES MONETARIOS >>>
     1. Cuando el usuario mencione â€œmargenâ€, â€œmargen brutoâ€ o â€œganancia brutaâ€, se debe consultar la informaciÃ³n en la columna 'Porcentaje_Margen_Bruto', que representa el **margen relativo** (porcentaje de utilidad sobre ventas).  
       Si el usuario pide explÃ­citamente â€œmargen en pesosâ€, â€œmargen monetarioâ€ o â€œmargen absolutoâ€, entonces usa la columna 'Margen_Bruto', que representa el **margen absoluto** (valor monetario de la utilidad bruta).  
       Ejemplo:  
       - â€œDame el margen bruto por mesâ€ â†’ usa `Porcentaje_Margen_Bruto`  
       - â€œDame el margen absoluto en pesosâ€ â†’ usa `Margen_Bruto`
    2. Cuando el usuario mencione â€œporcentaje de margenâ€, â€œ% margenâ€, â€œmargen porcentualâ€ o â€œmargen en porcentajeâ€, se debe consultar la informaciÃ³n en la columna 'Porcentaje_Margen_Bruto', que representa la proporciÃ³n del margen bruto sobre las ventas reales.
    3. Cuando el usuario mencione â€œunidades vendidasâ€, â€œcantidad de productos vendidosâ€ o â€œnÃºmero de ventasâ€, se estÃ¡ refiriendo al campo 'Unidades_Vendidas'.
    4. Cuando el usuario pregunte por â€œprecio promedioâ€, â€œvalor medio de ventaâ€ o â€œpromedio de preciosâ€, se refiere al campo 'Precio_Promedio', que corresponde al promedio del valor unitario de las ventas.
    5. Cuando el usuario mencione â€œventas realesâ€, â€œventas totalesâ€ o â€œvalor vendidoâ€, se estÃ¡ refiriendo al campo 'Ventas_Reales', que representa el total monetario facturado o reconocido como ingreso real.
    6. Cuando el usuario mencione â€œcostos realesâ€, â€œcostos totalesâ€ o â€œvalor del costoâ€, se refiere al campo Costo_Reales, que muestra el total de costos asociados a las ventas (sin incluir margen ni impuestos).
    7. Ejemplo: Si la pregunta es "Â¿cuÃ¡l es el total facturado?", la consulta deberÃ­a ser algo como `SELECT SUM(Ventas_Reales) FROM automundial;`. Aplica este patrÃ³n a otras mÃ©tricas.
    ---
    <<< REGLA CRÃTICA PARA FILTRAR POR FECHA >>>
    1. Tu tabla tiene una columna de fecha llamada `Fecha`.
    2. Si el usuario especifica un aÃ±o (ej: "del 2025", "en 2024"), SIEMPRE debes aÃ±adir una condiciÃ³n `WHERE YEAR(Fecha) = [aÃ±o]` a la consulta.
    3. Ejemplo: "dame las ventas de 2025" -> DEBE INCLUIR `WHERE YEAR(Fecha) = 2025`.
    ---
    <<< REGLA DE ORO PARA BÃšSQUEDA DE PRODUCTOS >>>
    1. Cuando el usuario mencione â€œartÃ­culoâ€, â€œproductoâ€, â€œÃ­temâ€, â€œreferenciaâ€, â€œnombre del repuestoâ€ o â€œnombre del materialâ€, se estÃ¡ refiriendo al campo 'Nombre_Articulo', el cual contiene el nombre comercial o tÃ©cnico de cada producto registrado en inventario o en las Ã³rdenes.
        Este campo puede incluir detalles como:
        - Medidas o especificaciones (ej. 195/60R16, 11R-22.5)
        - Marca o fabricante (ej. Yokohama, Firestone, Alliance)
        - Tipo o aplicaciÃ³n (ej. filtro de combustible, llanta, aire, repuesto)
    2. Si el usuario pregunta por un producto especÃ­fico, usa `WHERE LOWER(Nombre_Articulo) LIKE '%palabra%'.
    3. Cuando el usuario mencione â€œclienteâ€, â€œempresaâ€, â€œrazÃ³n socialâ€, â€œcompradorâ€, â€œcontratanteâ€ o â€œnombre del clienteâ€, se estÃ¡ refiriendo al campo 'Nombre_Cliente', que representa la entidad (persona natural o jurÃ­dica) a la que se le vendiÃ³, facturÃ³ o prestÃ³ un servicio.
    4. Cuando el usuario mencione â€œlÃ­neaâ€, â€œmarcaâ€, â€œfamilia de productoâ€, â€œreferencia comercialâ€ o â€œproveedor principalâ€, se estÃ¡ refiriendo al campo 'Nombre_Linea', el cual identifica la marca, lÃ­nea o categorÃ­a principal a la que pertenece un artÃ­culo.
    ---
    {hist_text}
    Pregunta del usuario: "{pregunta_usuario}"

    Devuelve SOLO la consulta SQL (sin explicaciones).
    """
    
    try:
        query_chain = create_sql_query_chain(llm_sql, db)
        sql_query_bruta = query_chain.invoke({"question": prompt_con_instrucciones})
        m = re.search(r'(?is)(select\b.+)$', sql_query_bruta.strip()); sql_query_limpia = m.group(1).strip() if m else sql_query_bruta.strip()
        sql_query_limpia = re.sub(r'(?is)^```sql|```$', '', sql_query_limpia).strip(); sql_query_limpia = _asegurar_select_only(sql_query_limpia)
        st.code(sql_query_limpia, language='sql')
        with st.spinner("â³ Ejecutando consulta..."):
            with db._engine.connect() as conn: df = pd.read_sql(text(sql_query_limpia), conn)
        st.success(f"âœ… Â¡Consulta ejecutada! Filas: {len(df)}")

        try:
            if not df.empty:
                # Extraer aÃ±o de la consulta SQL (si existe)
                year_match = re.search(r"YEAR\([^)]*\)\s*=\s*(\d{4})", sql_query_limpia)
                year_value = year_match.group(1) if year_match else None

                # Agregar columna AÃ±o solo si se detecta
                if year_value and "AÃ±o" not in df.columns:
                    df.insert(0, "AÃ±o", year_value)

                # ğŸ”¹ Detectar solo columnas numÃ©ricas que sÃ­ deben sumarse (evitar Mes, AÃ±o, Fecha...)
                value_cols = [
                    c for c in df.select_dtypes("number").columns
                    if not re.search(r"(?i)\b(mes|aÃ±o|dia|fecha)\b", c)
                ]

                # ğŸ”¹ Agregar fila Total si hay columnas de valor
                if value_cols:
                    total_row = {col: df[col].sum() if col in value_cols else "" for col in df.columns}
                    total_row[df.columns[0]] = "Total"  # siempre en la primera columna
                    df.loc[len(df)] = total_row

                # ğŸ¨ Estilo visual para la fila Total
                def highlight_total(row):
                    return [
                        "font-weight: bold; background-color: #f8f9fa; border-top: 2px solid #999;"
                        if str(row.iloc[0]).lower() == "total" else ""
                    ] * len(row)

                styled_df = df.style.apply(highlight_total, axis=1)
                return {"sql": sql_query_limpia, "df": df, "styled": styled_df}

        except Exception as e:
            st.warning(f"No se pudo aplicar formato ni totales: {e}")
            
        return {"sql": sql_query_limpia, "df": df}
    except Exception as e:
        st.warning(f"âŒ Error en la consulta directa. Intentando mÃ©todo alternativo... Detalle: {e}")
        return {"sql": None, "df": None, "error": str(e)}

def ejecutar_sql_en_lenguaje_natural(pregunta_usuario: str, hist_text: str):
    st.info("ğŸ¤” Activando el agente SQL experto como plan B.")
    prompt_sql = (f"Tu tarea es responder la pregunta consultando la tabla 'automundial'.\n{hist_text}\nDevuelve ÃšNICAMENTE una tabla en formato Markdown (con encabezados). NUNCA resumas ni expliques. El SQL interno NO DEBE CONTENER 'LIMIT' excepciÃ³n si el cliente lo solicita.\nPregunta: {pregunta_usuario}")
    try:
        with st.spinner("ğŸ’¬ Pidiendo al agente SQL que responda..."):
            res = agente_sql.invoke(prompt_sql)
            texto = res["output"] if isinstance(res, dict) and "output" in res else str(res)
        st.info("ğŸ“ Intentando convertir la respuesta en una tabla de datos..."); df_md = markdown_table_to_df(texto)
        if df_md.empty: st.warning("La conversiÃ³n de Markdown a tabla no produjo filas. Se mostrarÃ¡ la salida cruda.")
        return {"texto": texto, "df": df_md}
    except Exception as e:
        st.error(f"âŒ El agente SQL experto tambiÃ©n encontrÃ³ un problema: {e}")
        return {"texto": f"[SQL_ERROR] {e}", "df": pd.DataFrame()}
def analizar_con_datos(pregunta_usuario: str, hist_text: str, df: pd.DataFrame | None, feedback: str = None):
    st.info("\nğŸ§  El analista experto estÃ¡ examinando los datos...")
    correccion_prompt = ""
    if feedback:
        st.warning(f"âš ï¸ Reintentando con feedback: {feedback}")
        correccion_prompt = (f'INSTRUCCIÃ“N DE CORRECCIÃ“N: Tu respuesta anterior fue incorrecta. Feedback: "{feedback}". Genera una NUEVA respuesta corrigiendo este error.')
    preview = _df_preview(df, 50) or "(sin datos en vista previa; verifica la consulta)"
    prompt_analisis = f"""{correccion_prompt}\nEres IANA, un analista de datos senior EXTREMADAMENTE PRECISO y riguroso.\n---\n<<< REGLAS CRÃTICAS DE PRECISIÃ“N >>>\n1. **NO ALUCINAR**: NUNCA inventes nÃºmeros, totales, porcentajes o nombres de productos/categorÃ­as que no estÃ©n EXPRESAMENTE en la tabla de 'Datos'.\n2. **DATOS INCOMPLETOS**: Reporta los vacÃ­os (p.ej., "sin datos para Marzo") sin inventar valores.\n3. **VERIFICAR CÃLCULOS**: Antes de escribir un nÃºmero, revisa el cÃ¡lculo (sumas/conteos/promedios) con los datos.\n4. **CITAR DATOS**: Basa CADA afirmaciÃ³n que hagas en los datos visibles en la tabla.\n---\nPregunta Original: {pregunta_usuario}\n{hist_text}\nDatos para tu anÃ¡lisis (usa SÃ“LO estos):\n{preview}\n---\nFORMATO OBLIGATORIO:\nğŸ“Œ AnÃ¡lisis Ejecutivo de datos:\n1. Calcular totales y porcentajes clave.\n2. Detectar concentraciÃ³n.\n3. Identificar patrones temporales.\n4. Analizar dispersiÃ³n.\nEntregar el resultado en 3 bloques:\nğŸ“Œ Resumen Ejecutivo: hallazgos principales con nÃºmeros.\nğŸ” NÃºmeros de referencia: totales, promedios, ratios.\nâš  Importante: SÃ© muy breve, directo y diciente."""
    with st.spinner("ğŸ’¡ Generando anÃ¡lisis avanzado..."):
        analisis = llm_analista.invoke(prompt_analisis).content
    st.success("ğŸ’¡ Â¡AnÃ¡lisis completado!")
    return analisis
def responder_conversacion(pregunta_usuario: str, hist_text: str):
    st.info("ğŸ’¬ Activando modo de conversaciÃ³n...")
    prompt_personalidad = f"""Tu nombre es IANA, una IA amable de automundial. Ayuda a analizar datos.\nSi el usuario hace un comentario casual, responde amablemente de forma natural, muy humana y redirÃ­gelo a tus capacidades.\n{hist_text}\nPregunta: "{pregunta_usuario}" """
    respuesta = llm_analista.invoke(prompt_personalidad).content
    return {"texto": respuesta, "df": None, "analisis": None}

def generar_resumen_tabla(pregunta_usuario: str, res: dict) -> dict:
    st.info("âœï¸ Generando un resumen introductorio para la tabla...")
    df = res.get("df")
    if df is None or df.empty:
        return res

    # --- INICIO DE LA MODIFICACIÃ“N DEL PROMPT ---
    prompt = f"""
    ActÃºa como IANA, un analista de datos amable y servicial.
    Tu tarea es escribir una breve y conversacional introducciÃ³n para la tabla de datos que estÃ¡s a punto de mostrar.
    Basa tu respuesta en la pregunta del usuario para que se sienta como una continuaciÃ³n natural de la conversaciÃ³n.
    Si la respuesta no le gustÃ³ al USUARIO, disculpate es posible que le entendiste mal.
    
    IMPORTANTE: VarÃ­a tus respuestas. No uses siempre la misma frase "Por supuesto". Suena natural y humana.

    Pregunta del usuario: "{pregunta_usuario}"
    
    ---
    AquÃ­ tienes varios ejemplos de cÃ³mo responder:

    Ejemplo 1:
    Pregunta: "cuÃ¡les son los proveedores"
    Respuesta: "Â¡Listo! AquÃ­ tienes la lista de proveedores que encontrÃ©:"

    Ejemplo 2:
    Pregunta: "y sus ventas?"
    Respuesta: "He consultado las cifras de ventas. Te las muestro en la siguiente tabla:"

    Ejemplo 3:
    Pregunta: "y en q % esta su consumo?"
    Respuesta: "Perfecto, aquÃ­ estÃ¡ el desglose de los porcentajes de consumo que pediste:"

    Ejemplo 4:
    Pregunta: "dame el total por mes"
    Respuesta: "Claro que sÃ­. He preparado la tabla con los totales por mes:"
    ---

    Ahora, genera la introducciÃ³n para la pregunta del usuario actual:
    """
    # --- FIN DE LA MODIFICACIÃ“N DEL PROMPT ---
    try:
        introduccion = llm_analista.invoke(prompt).content
        res["texto"] = introduccion
    except Exception as e:
        st.warning(f"No se pudo generar el resumen introductorio. Error: {e}")
        res["texto"] = "AquÃ­ estÃ¡n los datos que solicitaste:"
    return res

# ============================================
# 4) Orquestador y ValidaciÃ³n
# ============================================
def validar_y_corregir_respuesta_analista(pregunta_usuario: str, res_analisis: dict, hist_text: str) -> dict:
    MAX_INTENTOS = 2
    for intento in range(MAX_INTENTOS):
        st.info(f"ğŸ•µï¸â€â™€ï¸ Supervisor de Calidad: Verificando anÃ¡lisis (Intento {intento + 1})..."); contenido_respuesta = res_analisis.get("analisis", "") or ""
        if not contenido_respuesta.strip(): return {"tipo": "error", "texto": "El anÃ¡lisis generado estaba vacÃ­o."}
        df_preview = _df_preview(res_analisis.get("df"), 50) or "(sin vista previa de datos)"
        prompt_validacion = f"""Eres un supervisor de calidad estricto. Valida si el 'AnÃ¡lisis' se basa ESTRICTAMENTE en los 'Datos de Soporte'.\nFORMATO:\n- Si estÃ¡ 100% basado en los datos: APROBADO\n- Si alucina/inventa/no es relevante: RECHAZADO: [razÃ³n corta y accionable]\n---\nPregunta: "{pregunta_usuario}"\nDatos de Soporte:\n{df_preview}\n---\nAnÃ¡lisis a evaluar:\n\"\"\"{contenido_respuesta}\"\"\"\n---\nEvaluaciÃ³n:"""
        try:
            resultado = llm_validador.invoke(prompt_validacion).content.strip(); up = resultado.upper()
            if up.startswith("APROBADO"):
                st.success("âœ… AnÃ¡lisis aprobado por el Supervisor."); return res_analisis
            elif up.startswith("RECHAZADO"):
                feedback_previo = resultado.split(":", 1)[1].strip() if ":" in resultado else "RazÃ³n no especificada."
                st.warning(f"âŒ AnÃ¡lisis rechazado. Feedback: {feedback_previo}")
                if intento < MAX_INTENTOS - 1:
                    st.info("ğŸ”„ Regenerando anÃ¡lisis con feedback...")
                    res_analisis["analisis"] = analizar_con_datos(pregunta_usuario, hist_text, res_analisis.get("df"), feedback=feedback_previo)
                else: return {"tipo": "error", "texto": "El anÃ¡lisis no fue satisfactorio incluso despuÃ©s de una correcciÃ³n."}
            else: return {"tipo": "error", "texto": f"Respuesta ambigua del validador: {resultado}"}
        except Exception as e: return {"tipo": "error", "texto": f"ExcepciÃ³n durante la validaciÃ³n: {e}"}
    return {"tipo": "error", "texto": "Se alcanzÃ³ el lÃ­mite de intentos de validaciÃ³n."}



def clasificar_intencion(pregunta: str) -> str:
    # <<< MODIFICADO para mejorar la detecciÃ³n de consultas de datos >>>
    prompt_orq = f"""
Clasifica la intenciÃ³n del usuario en UNA SOLA PALABRA. Presta especial atenciÃ³n a los verbos de acciÃ³n y palabras clave.

1. `analista`: Si la pregunta pide explÃ­citamente una interpretaciÃ³n, resumen, comparaciÃ³n o explicaciÃ³n.
   PALABRAS CLAVE PRIORITARIAS: analiza, compara, resume, explica, por quÃ©, tendencia, insights, dame un anÃ¡lisis, haz un resumen, interpreta.
   Si una de estas palabras clave estÃ¡ presente, la intenciÃ³n SIEMPRE es `analista`.

2. `consulta`: Si la pregunta pide datos crudos (listas, conteos, totales, valores, mÃ©tricas) o resultados numÃ©ricos directos, y NO contiene palabras clave de `analista`.
   Ejemplos: 'cuÃ¡ntos proveedores hay', 'lista todos los productos', 'muÃ©strame el total', 'ventas por mes', 'margen por cliente', 'costo total', 'precio promedio'.
   PALABRAS CLAVE ADICIONALES: venta, ventas, costo, costos, margen, precio, unidades, rubro, cliente, artÃ­culo, producto, lÃ­nea, familia, total, facturado, utilidad.

3. `correo`: Si la pregunta pide explÃ­citamente enviar un correo, email o reporte.
   PALABRAS CLAVE: envÃ­a, mandar, correo, email, reporte a, envÃ­ale a.

4. `conversacional`: Si es un saludo o una pregunta general no relacionada con datos.
   Ejemplos: 'hola', 'gracias', 'quÃ© puedes hacer', 'cÃ³mo estÃ¡s'.

Pregunta: "{pregunta}"
ClasificaciÃ³n:
"""

    try:
        opciones = {"consulta", "analista", "conversacional", "correo"}
        r = llm_orq.invoke(prompt_orq).content.strip().lower().replace('"', '').replace("'", "")

        # ğŸ”¹ Refuerzo semÃ¡ntico (fallback inteligente)
        # Si contiene palabras tÃ­picas de consultas de datos, fuerza 'consulta'
        if any(pal in pregunta.lower() for pal in [
            "venta", "ventas", "margen", "costo", "costos", "precio", "unidades",
            "rubro", "cliente", "artÃ­culo", "producto", "lÃ­nea", "familia", "total", "facturado"
        ]):
            return "consulta"

        # Si el modelo devuelve algo fuera de las opciones vÃ¡lidas â†’ se asume consulta
        if r not in opciones:
            return "consulta"

        return r

    except Exception:
        return "consulta"

def obtener_datos_sql(pregunta_usuario: str, hist_text: str) -> dict:
    if any(keyword in pregunta_usuario.lower() for keyword in ["anterior", "esos datos", "esa tabla"]):
        for msg in reversed(st.session_state.get('messages', [])):
            if msg.get('role') == 'assistant':
                content = msg.get('content', {}); df_prev = content.get('df')
                if isinstance(df_prev, pd.DataFrame) and not df_prev.empty:
                    st.info("ğŸ’¡ Usando datos de la respuesta anterior para la nueva solicitud.")
                    return {"df": df_prev}
    res_real = ejecutar_sql_real(pregunta_usuario, hist_text)
    if res_real.get("df") is not None and not res_real["df"].empty:
        return res_real
    return ejecutar_sql_en_lenguaje_natural(pregunta_usuario, hist_text)

def orquestador(pregunta_usuario: str, chat_history: list):
    with st.expander("âš™ï¸ Ver Proceso de IANA", expanded=False):
        hist_text = get_history_text(chat_history)
        clasificacion = clasificar_intencion(pregunta_usuario)
        st.success(f"âœ… Â¡IntenciÃ³n detectada! Tarea: {clasificacion.upper()}.")

        if clasificacion == "conversacional":
            return responder_conversacion(pregunta_usuario, hist_text)
        
        if clasificacion == "correo":
            df_para_enviar = None
            for msg in reversed(st.session_state.get('messages', [])):
                if msg.get('role') == 'assistant':
                    content = msg.get('content', {}); df_prev = content.get('df')
                    if isinstance(df_prev, pd.DataFrame) and not df_prev.empty:
                        df_para_enviar = df_prev
                        st.info("ğŸ“§ Datos de la tabla anterior encontrados para adjuntar al correo.")
                        break
            
            if df_para_enviar is None:
                st.warning("No encontrÃ© una tabla en la conversaciÃ³n reciente para enviar. El correo irÃ¡ sin datos adjuntos.")

            detalles = extraer_detalles_correo(pregunta_usuario)
            return enviar_correo_agente(
                recipient=detalles["recipient"],
                subject=detalles["subject"],
                body=detalles["body"],
                df=df_para_enviar
            )

        res_datos = obtener_datos_sql(pregunta_usuario, hist_text)
        if res_datos.get("df") is None or res_datos["df"].empty:
            return {"tipo": "error", "texto": "Lo siento, no pude obtener datos para tu pregunta. Intenta reformularla."}

        #if clasificacion == "consulta":
        #    st.success("âœ… Consulta directa completada.")
        #    return interpretar_resultado_sql(res_datos)


        if clasificacion == "consulta":
            st.success("âœ… Consulta directa completada.")
            # Primero, intentamos interpretar el resultado como siempre
            res_interpretado = interpretar_resultado_sql(res_datos)
    
            # Luego, si no se generÃ³ texto (porque es una tabla), creamos la introducciÃ³n
            if res_interpretado.get("texto") is None and res_interpretado.get("df") is not None and not res_interpretado["df"].empty:
                res_interpretado = generar_resumen_tabla(pregunta_usuario, res_interpretado)
    
            return res_interpretado

        if clasificacion == "analista":
            st.info("ğŸ§  Generando anÃ¡lisis inicial...")
            res_datos["analisis"] = analizar_con_datos(pregunta_usuario, hist_text, res_datos.get("df"))
            return validar_y_corregir_respuesta_analista(pregunta_usuario, res_datos, hist_text)

# ============================================
# 5) Interfaz: MicrÃ³fono en vivo + Chat
# ============================================

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": {"texto": "Â¡Hola! Soy IANA, tu asistente de IA de automundial. Â¿QuÃ© te gustarÃ­a saber?"}}]

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        content = message.get("content", {});
        if isinstance(content, dict):
            if content.get("texto"): st.markdown(content["texto"])
            if isinstance(content.get("df"), pd.DataFrame) and not content["df"].empty: st.dataframe(content["df"])
            if content.get("analisis"): st.markdown(content["analisis"])
        elif isinstance(content, str): st.markdown(content)

st.markdown("### ğŸ¤ Habla con IANA o escribe tu pregunta")
lang = st.secrets.get("stt_language", "es-CO")

# Unificar el procesamiento de la pregunta
def procesar_pregunta(prompt):
    if prompt:
        if not all([db, llm_sql, llm_analista, llm_orq, agente_sql, llm_validador]):
            st.error("La aplicaciÃ³n no estÃ¡ completamente inicializada. Revisa los errores de conexiÃ³n o de API key.")
            return

        st.session_state.messages.append({"role": "user", "content": {"texto": prompt}})
        with st.chat_message("user"): st.markdown(prompt)
        with st.chat_message("assistant"):
            res = orquestador(prompt, st.session_state.messages)
            st.session_state.messages.append({"role": "assistant", "content": res})
            if res and res.get("tipo") != "error":
                if res.get("texto"): st.markdown(res["texto"])
                if isinstance(res.get("df"), pd.DataFrame) and not res["df"].empty: st.dataframe(res["df"])
                if res.get("analisis"):
                    st.markdown("---"); st.markdown("### ğŸ§  AnÃ¡lisis de IANA"); st.markdown(res["analisis"])
                    st.toast("AnÃ¡lisis generado âœ…", icon="âœ…")
            elif res:
                st.error(res.get("texto", "OcurriÃ³ un error inesperado."))
                st.toast("Hubo un error âŒ", icon="âŒ")

# Contenedor para los inputs
input_container = st.container()
with input_container:
    col1, col2 = st.columns([1, 4])
    with col1:
        voice_text = speech_to_text(language=lang, start_prompt="ğŸ™ï¸ Hablar", stop_prompt="ğŸ›‘ Detener", use_container_width=True, just_once=True, key="stt")
    with col2:
        prompt_text = st.chat_input("... o escribe tu pregunta aquÃ­")

# Determinar quÃ© prompt usar
prompt_a_procesar = None
if voice_text:
    prompt_a_procesar = voice_text
elif prompt_text:
    prompt_a_procesar = prompt_text

# Procesar el prompt si existe
if prompt_a_procesar:
    procesar_pregunta(prompt_a_procesar)
    

